# ğŸ§  Hybrid Multi-Modal RAG Pipeline â€” Aparavi Coding Challenge

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline capable of processing **multi-modal, multilingual PDF documents** â€” including invoices, tables, scanned files, and text in **English and German** â€” and answering questions with **document-grounded citations**.

---

## ğŸš€ Features

- âœ… **Multi-modal document ingestion** (scanned PDFs, machine-readable, tables)
- âœ… **Agentic OCR routing** (Google Vision API + Tesseract fallback)
- âœ… **Table extraction** (Camelot)
- âœ… **Hybrid retrieval** (vector + SQL)
- âœ… **Multilingual support** (English + German)
- âœ… **Source-cited answers** using GPT-4o
- âœ… **RAG evaluation** (F1, precision, recall)

---

## ğŸ—‚ï¸ Architecture

```text
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  PDF File  â”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚ OCR Agent   â”‚â”€â”€Google Vision / Tesseract
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Text + Tables â”‚ â† Camelot + PyMuPDF
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Chunking + Lang â”‚ â† Text split + langdetect
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Vector DB (Qdrant)   â”‚ â† `store_chunks`
 â”‚ SQL DB (SQLite)      â”‚ â† `store_table_rows`
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Hybrid Retriever      â”‚ â† vector + SQL union
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Answer Generator      â”‚ â† GPT-4o with citations
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§± Tech Stack

| Component           | Tool / Lib                      |
| ------------------- | ------------------------------- |
| PDF Parsing         | PyMuPDF                         |
| OCR (fallback)      | Tesseract OCR                   |
| OCR (commercial)    | Google Vision API               |
| Table Extraction    | Camelot                         |
| Vector Store        | Qdrant                          |
| SQL Store           | SQLite                          |
| Embedding Model     | OpenAI `text-embedding-3-small` |
| RAG + QA            | GPT-4o                          |
| Graph Orchestration | LangGraph                       |
| Evaluation          | Arize Phoenix (planned)         |

---

## ğŸ§ª Running the Project

### 1. ğŸ³ Prerequisites

- Docker + Docker Compose
- OpenAI API key (`OPENAI_API_KEY`)
- Google Vision credentials (optional, for full OCR agent)

### 2. ğŸ—ï¸ ETL Pipeline

```bash
docker-compose run app python src/test/test_etl_graph.py
```

### 3. ğŸ” RAG Inference

```bash
docker-compose run app python src/test/test_rag_graph_run.py
```

### 4. ğŸ§ª Evaluation (Optional)

```bash
docker-compose run app python src/eval/evaluate_rag.py
```

---

## ğŸ¤– OCR Decision Logic

The **OCR agent** runs only on pages with no extractable text:

- âœ… If PyMuPDF returns empty â†’ run **Google Vision API**
- ğŸ” If API quota fails â†’ fallback to **Tesseract**

This saves cost and speeds up processing.

---

## ğŸ§  Hybrid Retrieval

```python
vector_chunks = search_vector(query, k=5)
sql_chunks = search_sql_chunks(language=detected_lang, limit=5)
```

The results are merged and passed to GPT-4o, ensuring both fuzzy and symbolic matches (especially from tables) are included.

---

## ğŸ§¾ Example Output

> **Question**: What is the invoice total?  
> **Answer**: The total is 101,63 EUR. _(doc: 72682299427_pdf, page: 1)_

---

## ğŸ› ï¸ Evaluation Strategy

- Compare answers from GPT to ground-truth from the Q&A Excel
- Use precision, recall, and F1 metrics
- Evaluate both exact and partial match support

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ pdf_extractor.py
â”‚   â”œâ”€â”€ table_extractor.py
â”œâ”€â”€ transform/
â”‚   â”œâ”€â”€ text_chunker.py
â”‚   â”œâ”€â”€ language_detector.py
â”œâ”€â”€ store/
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ sql_store.py
â”œâ”€â”€ retrieve/
â”‚   â”œâ”€â”€ sql_retriever.py
â”‚   â”œâ”€â”€ vector_retriever.py
â”‚   â”œâ”€â”€ hybrid_retriever.py
â”œâ”€â”€ generate/
â”‚   â””â”€â”€ response_generator.py
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ etl_graph.py
â”‚   â””â”€â”€ rag_graph.py
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ test_etl_graph.py
â”‚   â”œâ”€â”€ test_rag_graph_run.py
â”‚   â”œâ”€â”€ test_generate_answer.py
â”‚   â””â”€â”€ ...
```

---
